{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 1: Prompt Engineering and Agents\n",
    "\n",
    "The LLM is a function `(input: string) -> string` that can be used for any purpose. Prompt engineering lets us do better than strings, more like: `(input: PromptTemplate) -> AgentResponse`.\n",
    "\n",
    "**Prompt Engineering:** pretty much any LLM prompt that gets output beyond the normal completion/chat behavior:\n",
    "\n",
    "* General-purpose NLP tasks: categorization, clustering, entity extraction, summarization, translation... Pretty much everything [More in Example #1]. Or playing D&D, pretending to be a bash shell, etc.\n",
    "\n",
    "* Or large improvements on problem-solving benchmarks by including simple phrases like \"Lets think step by step\" (Large Language Models are Zero-Shot Reasoners: https://arxiv.org/abs/2205.11916)\n",
    "\n",
    "* Or Jailbreaks! (DAN prompt: https://github.com/0xk1h0/ChatGPT_DAN) - Not all fun and games, these could become a serious security concern as LLMs become more widely adopted as tools...\n",
    "\n",
    "**Agent:** A piece of code that queries the LLM with a prompt engineered to give structured output. The code usually parses the output and then takes some action before returning a final response. The actions the code takes can be iterative (repeatedly prompting the LLM) until the final response is determined. *The LLM as a tool.*\n",
    "\n",
    "* \"By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers.\" (Large Language Models Are Human-Level Prompt Engineers; https://arxiv.org/abs/2211.01910)\n",
    "\n",
    "* \"Techniques to improve reliability\" and its citations is the best starting point (https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)\n",
    "\n",
    "* Langchain, AutoGPT, JARVIS, even ChatGPT plugins are all built on this core idea.\n",
    "\n",
    "*(NOTE: Follow the normal setup instructions in README.md before running this notebook!)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to make imports from src/ work (skip ahead)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Chat Completion API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1683231674,\n",
      "  \"id\": \"chatcmpl-7CZjuzxRmzXRWiQtVH9Y0QtQ5z6fn\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 9,\n",
      "    \"prompt_tokens\": 15,\n",
      "    \"total_tokens\": 24\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llm import chat_completion # <-- gpt-toolbox's small wrapper around the openai ChatCompletion API\n",
    "\n",
    "# the API gives us 3 parts to the prompt: system, examples, and user (https://platform.openai.com/docs/api-reference/chat)\n",
    "\n",
    "system = \"\"\n",
    "examples = []\n",
    "user = \"Hi?\"\n",
    "\n",
    "print(chat_completion(system, examples, user))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example #1: A prompt for NLP tasks**\n",
    "\n",
    "Lets \"engineer a prompt\" to get GPT to categorize, summarize, extract entities, and translate to french."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Category: Business\\nSummary: Ice cream truck operators in New York must be licensed and permitted to comply with city rules and regulations.\\nEntities: New York, ice cream trucks, park, food vendors, city rules and regulations\\nFrench: Les op\\u00e9rateurs de camions de cr\\u00e8me glac\\u00e9e \\u00e0 New York doivent \\u00eatre autoris\\u00e9s et autoris\\u00e9s \\u00e0 se conformer aux r\\u00e8gles et r\\u00e8glements de la ville.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1683231675,\n",
      "  \"id\": \"chatcmpl-7CZjv3MzpOjvO5USXis04nwdanuE0\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 87,\n",
      "    \"prompt_tokens\": 157,\n",
      "    \"total_tokens\": 244\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system = \"\"\"\n",
    "Given the user's input, output:\n",
    "Category:<one of the following: \"news\", \"science\", \"politics\", \"sports\", \"entertainment\", \"business\", \"health\", \"technology\", \"world\">\n",
    "Summary:<one sentence summary>\n",
    "Entities:<list of entities, comma separated>\n",
    "French:<French translation>\n",
    "\"\"\"\n",
    "\n",
    "examples = []\n",
    "\n",
    "def nlp_tasks_template(input): return f\"\"\"\n",
    "Input: {input}\n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "q = \"Ice cream trucks are a ubiquitous part of summer in New York, and a staple at city parks. So if you live right by a park, the trucks, with their incessant jingles and rattling generators, come with the territory. However, the truck operators, like other food vendors, must be licensed and permitted, and comply with city rules and regulations. \"\n",
    "\n",
    "response = chat_completion(system, examples, nlp_tasks_template(q))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's structured output, we can parse it with a regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Category\": \" Business\",\n",
      "    \"Summary\": \" Ice cream truck operators in New York must be licensed and permitted to comply with city rules and regulations.\",\n",
      "    \"Entities\": \" New York, ice cream trucks, park, food vendors, city rules and regulations\",\n",
      "    \"French\": \" Les op\\u00e9rateurs de camions de cr\\u00e8me glac\\u00e9e \\u00e0 New York doivent \\u00eatre autoris\\u00e9s et autoris\\u00e9s \\u00e0 se conformer aux r\\u00e8gles et r\\u00e8glements de la ville.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def parse_nlp_tasks_completion(response):\n",
    "    completion = response.choices[0].message.content\n",
    "    output_pattern = re.compile(\n",
    "        r\"Category:(?P<Category>[^\\n]+)\\n\"\n",
    "        r\"Summary:(?P<Summary>[^\\n]+)\\n\"\n",
    "        r\"Entities:(?P<Entities>[^\\n]+)\\n\" \n",
    "        r\"French:(?P<French>[^\\n]+)\\n?\")\n",
    "\n",
    "    match = output_pattern.match(completion)\n",
    "\n",
    "    return match.groupdict()\n",
    "\n",
    "parsed = parse_nlp_tasks_completion(response)\n",
    "\n",
    "parsed = json.dumps(parsed, indent=4)\n",
    "\n",
    "print(parsed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And build on top of it arbitrarily..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " J'aime la crème glacée.\n"
     ]
    }
   ],
   "source": [
    "def to_french(text):\n",
    "    response = chat_completion(system, examples, nlp_tasks_template(text))\n",
    "    parsed = parse_nlp_tasks_completion(response)\n",
    "    return parsed[\"French\"]\n",
    "\n",
    "print(to_french(\"I like ice cream.\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With about 10 lines of code, we have a function that translates anything to French. Or, extract entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ice cream, Paris, Pizza, New York\n"
     ]
    }
   ],
   "source": [
    "def extracy_entities(text):\n",
    "    response = chat_completion(system, examples, nlp_tasks_template(text))\n",
    "    parsed = parse_nlp_tasks_completion(response)\n",
    "    return parsed[\"Entities\"]\n",
    "\n",
    "print(extracy_entities(\"I like to eat ice cream in Paris and Pizza in New York.\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Core Ideas\n",
    "\n",
    "1. The LLM is a function `(input: string) -> string`\n",
    "2. \"Prompt Engineering\" is the act of getting special output from the LLM. One application of this is getting structured (ie, parseable) output.\n",
    "3. We can easily build programs that hit the LLM with prompts designed for specialized purposes, parse the output, and do stuff.\n",
    "4. *The LLM is a tool*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
